{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20c8f090-6a9e-4540-bfc8-414bf9f02ad8",
   "metadata": {},
   "source": [
    "Project 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b4fe86-7e0d-48bf-81ff-1353df60deb9",
   "metadata": {},
   "source": [
    "FaultFindy (Build intelligence using Machine Learning to predict the faulty tyre in manufacturing)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "88186704-4cda-417e-ad2d-e7aab73a3b2d",
   "metadata": {},
   "source": [
    "1. Data Collection\n",
    "Objective: Gather historical manufacturing data, including good and faulty tire images.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Download and extract the dataset from the provided zip file.\n",
    "Ensure data quality, handle missing values, and remove outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c816b0f-1ade-4884-9ab0-b344c550fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "manufacturing_data = pd.read_csv('manufacturing_data.csv')\n",
    "faulty_images = pd.read_csv('faulty_images.csv')\n",
    "good_images = pd.read_csv('good_images.csv')\n",
    "\n",
    "# Check for missing values and outliers\n",
    "manufacturing_data.info()\n",
    "manufacturing_data.describe()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11402fbe-da82-4345-bf99-cc4a3e436695",
   "metadata": {},
   "source": [
    "2. Data Preprocessing\n",
    "Objective: Clean and preprocess the data to remove noise and inconsistencies.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Handle missing values by imputation or removal.\n",
    "Standardize or normalize numerical features.\n",
    "Augment image data if necessary (e.g., rotation, flipping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15883135-f08f-47e4-ac96-041f28afd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and preprocess the data\n",
    "# Handle missing values\n",
    "manufacturing_data.dropna(inplace=True)\n",
    "\n",
    "# Normalize numerical features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "manufacturing_data[numerical_cols] = scaler.fit_transform(manufacturing_data[numerical_cols])\n",
    "\n",
    "# Augment image data\n",
    "# Augmentation steps...\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb8ccb7c-9f72-4d28-80c6-a5dde573b67e",
   "metadata": {},
   "source": [
    "3. Feature Engineering\n",
    "Objective: Identify important features and process variables that influence faulty tire generation.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Analyze correlation between features and target variable.\n",
    "Engineer relevant features to capture patterns and correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6a0e0d-9b78-43cd-b0b9-ead5a4cf9805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature correlation\n",
    "correlation_matrix = manufacturing_data.corr()\n",
    "\n",
    "# Engineer relevant features\n",
    "# Feature engineering steps...\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "11430a23-6aec-43fb-9d18-a5d9cc445f38",
   "metadata": {},
   "source": [
    "4. Model Selection\n",
    "Objective: Choose appropriate machine and deep learning algorithms.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Explore models like logistic regression, decision trees, random forests, gradient boosting, CNNs for computer vision.\n",
    "Choose models based on performance and complexity trade-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d3bbcb-18f7-44cf-8d95-3d094b1c0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Machine Learning Models\n",
    "model_rf = RandomForestClassifier()\n",
    "\n",
    "# Deep Learning Models\n",
    "model_cnn = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, img_channels)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "929e5d09-1540-4e2a-aff8-e68d78ac97d6",
   "metadata": {},
   "source": [
    "5. Model Training\n",
    "Objective: Train the selected machine learning models on the training data.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Split the data into training and testing sets.\n",
    "Train the models using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cca21b0-dfb5-412d-b616-1ad478384069",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the models\n",
    "model_rf.fit(X_train, y_train)\n",
    "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model_cnn.fit(X_train_images, y_train, epochs=10, validation_data=(X_test_images, y_test))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4606ebf7-30e9-4e23-9719-24e241f0de08",
   "metadata": {},
   "source": [
    "6. Model Evaluation\n",
    "Objective: Evaluate the models' performance using relevant metrics.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Evaluate models' performance using metrics like accuracy, precision, recall, F1-score.\n",
    "Choose the best-performing model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b7ccc5-bf84-431f-a1ea-b2184cbb0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Machine Learning Models\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# Evaluate Deep Learning Models\n",
    "loss, accuracy = model_cnn.evaluate(X_test_images, y_test)\n",
    "\n",
    "# Choose the best-performing model\n",
    "best_model = model_rf if accuracy_rf > accuracy else model_cnn\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef88afc6-e985-45fc-939d-2ddb297c8098",
   "metadata": {},
   "source": [
    "7. Hyperparameter Tuning\n",
    "Objective: Fine-tune hyperparameters of the selected model to optimize performance.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Use techniques like grid search or random search for hyperparameter optimization.\n",
    "Validate the tuned model to ensure improved performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a8c22-c4b9-4cd6-aa56-12b8e8992588",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca90812-9967-409c-87dc-8b54d70eacc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
