{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fbaf770a-31e5-4454-9d23-ce635130c015",
   "metadata": {},
   "source": [
    "Project 4\n",
    "For-rest from Fires (Fire Detection Model using Deep Learning)\n",
    "Problem Statement:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cadca963-0e35-449f-918f-f86ddf7a5730",
   "metadata": {},
   "source": [
    "Step 1: Data Collection\n",
    "You will need to download and unzip the dataset before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ccbe7a-3392-4854-88be-199f688c4e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "# Unzip the dataset\n",
    "with zipfile.ZipFile('FOREST_FIRE_SMOKE_AND_NON_FIRE_DATASET.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('dataset')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3344cd49-689f-47a2-9bf4-c13acbbdea85",
   "metadata": {},
   "source": [
    "Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98636000-17a2-4d3f-8166-5e46ba6e11e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define directories\n",
    "train_dir = os.path.join('dataset', 'train')\n",
    "validation_dir = os.path.join('dataset', 'validation')\n",
    "test_dir = os.path.join('dataset', 'test')\n",
    "\n",
    "# Define ImageDataGenerator for data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9794e7ec-ea41-4682-b23b-f977852e9e7d",
   "metadata": {},
   "source": [
    "Step 3: Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc0bf55-d0c7-4a77-b0af-ccbd4855a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "# Define the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c865692-cd0f-41a6-be8c-4c7657c96ba3",
   "metadata": {},
   "source": [
    "Step 4: Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a820676-5c6a-4fc3-afe2-159c825d977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "771045c6-602f-4267-9c98-6907aede2cce",
   "metadata": {},
   "source": [
    "Step 5: Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd05084-bbdb-49a1-8c6d-3c8d93232c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n",
    "\n",
    "# Plot training and validation accuracy and loss\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, acc, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, loss, label='Training Loss')\n",
    "plt.plot(epochs, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4275fc4e-e8aa-4cbe-a485-c9f7287f3a88",
   "metadata": {},
   "source": [
    "Step 6: Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec669168-1e59-427a-996c-97871f856b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Define a new model with tuned hyperparameters\n",
    "model_tuned = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_tuned.compile(optimizer=RMSprop(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_tuned = model_tuned.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")\n",
    "\n",
    "# Evaluate the tuned model\n",
    "test_loss_tuned, test_acc_tuned = model_tuned.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Tuned Test accuracy: {test_acc_tuned:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9e62b14a-0fb1-43a0-9740-eec9201d0613",
   "metadata": {},
   "source": [
    "Step 7: Model Deployment Plan\n",
    "Model Serialization: Save the trained model using model.save('fire_detection_model.h5').\n",
    "Model Serving: Deploy the model using TensorFlow Serving or a web framework like Flask for real-time prediction.\n",
    "Integration: Integrate the model into the surveillance system for real-time fire detection.\n",
    "Monitoring: Continuously monitor the model's performance and update it with new data to maintain high accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a844cc40-2829-46e6-8066-c31cd17ec9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
