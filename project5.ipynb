{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c04f0b6-8d1a-47ef-b79a-57ec64205233",
   "metadata": {},
   "source": [
    "Project 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ba14504-e726-4c95-af89-0fdc9fe9413d",
   "metadata": {},
   "source": [
    "\n",
    "MoodforMusic (An Intelligent Mood Detection and Music Recommendation Application)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c006be-9264-4413-80e9-65f8e5ffbf2c",
   "metadata": {},
   "source": [
    "Step 1: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c313b931-d5a3-4ce3-a015-c2371d1c7c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code to load dataset\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile('MoodforMusic.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('MoodforMusic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3249ae4-7692-485e-85ba-1de5e66aa39f",
   "metadata": {},
   "source": [
    "Step 2: Image/Video Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92539c23-33c1-4f05-b654-b961b86b156b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image\n",
    "\n",
    "# Example usage\n",
    "image_path = 'path_to_image.jpg'\n",
    "preprocessed_image = preprocess_image(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74df4bec-5bdc-4339-a039-5434787c59a5",
   "metadata": {},
   "source": [
    "Step 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8c0158-e684-463f-961e-9d410c9c56e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(image_path):\n",
    "    model = VGG16(weights='imagenet', include_top=False)\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    features = model.predict(img_data)\n",
    "    return features\n",
    "\n",
    "# Example usage\n",
    "features = extract_features(image_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7c07b5-3d85-4d29-9761-e0756bda0cab",
   "metadata": {},
   "source": [
    "Step 4: Mood Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fa6258-3c7d-492b-94f1-bd091a6ca6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm_model(X_train, y_train):\n",
    "    model = SVC(kernel='linear', probability=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "X_train = np.array([...])  # feature vectors\n",
    "y_train = np.array([...])  # labels\n",
    "model = train_svm_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2551c58-0175-4905-a62d-20bfb2e62327",
   "metadata": {},
   "source": [
    "5. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ed72ef6-6d11-4a85-b2d3-ad28a0e59b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Happy Song']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array([...])  # feature vectors\n",
    "y = np.array([...])  # labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = train_svm_model(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e6be3-f656-4859-b9e0-f8135f4c774f",
   "metadata": {},
   "source": [
    "Step Music Recommendation Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3c1c0-1754-494a-92dc-d86e2f64d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_image():\n",
    "    file = request.files['image']\n",
    "    # Process the image and predict mood\n",
    "    mood = predict_mood(file)\n",
    "    recommendations = recommend_music(mood)\n",
    "    return render_template('result.html', mood=mood, recommendations=recommendations)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c64d07-30fc-4b80-a741-fedb2489b069",
   "metadata": {},
   "source": [
    "7. User Interface Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee84fab-0254-4d79-8bb4-83109eccee14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "import os\n",
    "from werkzeug.utils import secure_filename\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config['UPLOAD_FOLDER'] = 'static/uploads/'\n",
    "\n",
    "if not os.path.exists(app.config['UPLOAD_FOLDER']):\n",
    "    os.makedirs(app.config['UPLOAD_FOLDER'])\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/upload', methods=['POST'])\n",
    "def upload_image():\n",
    "    if 'image' not in request.files:\n",
    "        return redirect(request.url)\n",
    "    \n",
    "    file = request.files['image']\n",
    "    if file.filename == '':\n",
    "        return redirect(request.url)\n",
    "\n",
    "    if file:\n",
    "        filename = secure_filename(file.filename)\n",
    "        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)\n",
    "        file.save(filepath)\n",
    "        \n",
    "        mood, recommendations = process_and_recommend(filepath)\n",
    "        \n",
    "        return render_template('result.html', mood=mood, recommendations=recommendations, image_path=filepath)\n",
    "\n",
    "def process_and_recommend(image_path):\n",
    "    # Dummy implementation for demonstration\n",
    "    mood = \"happy\"\n",
    "    recommendations = [\"Happy Song 1\", \"Happy Song 2\", \"Happy Song 3\"]\n",
    "    return mood, recommendations\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b77111a-43c6-47e8-b8e3-3f15dfe9d81f",
   "metadata": {},
   "source": [
    "8. Integration"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b09a3f1-e870-4e24-a590-26c1e2453e09",
   "metadata": {},
   "source": [
    " Integration is demonstrated in the Flask app and process_and_recommend function above.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1962e331-55c0-4988-9454-6265a47472b8",
   "metadata": {},
   "source": [
    "9. Testing and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3496f6f9-97e7-4abb-be98-2fa0ed023ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\r\n",
    "\r\n",
    "def evaluate_model(X_test, y_test, model):\r\n",
    "    y_pred = model.predict(X_test)\r\n",
    "    accuracy = accuracy_score(y_test, y_pred)\r\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\r\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\r\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\r\n",
    "    return accuracy, precision, recall, f1\r\n",
    "\r\n",
    "accuracy, precision, recall, f1 = evaluate_model(X_test, y_test, model)\r\n",
    "print(f'Accuracy: {accuracy}')\r\n",
    "print(f'Precision: {precision}')\r\n",
    "print(f'Recall: {recall}')\r\n",
    "print(f'F1 Score: {f1}')\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2de16b-12f0-4868-bca1-4481da178d8c",
   "metadata": {},
   "source": [
    "10. Model Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd962ec-fbff-40b6-ae12-6d5f29b11b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.1, 1, 10], 'gamma': [1, 0.1, 0.01], 'kernel': ['rbf', 'linear']}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa8b5f7-651a-4df2-8e74-85bd228f602d",
   "metadata": {},
   "source": [
    "11. Documentation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecdc070e-5127-48bf-b93a-6564a674bdc4",
   "metadata": {},
   "source": [
    "Objective: Prepare comprehensive documentation explaining the entire project, including the technical aspects and usage instructions.\n",
    "Steps:\n",
    "\n",
    "Document the project overview, design choices, implementation details, and user instructions.\n",
    "Provide code snippets, diagrams, and screenshots where necessary.\n",
    "Documentation Outline:\n",
    "\n",
    "Project Overview\n",
    "Design Choices and Architecture\n",
    "Data Collection and Preprocessing\n",
    "Feature Extraction and Model Training\n",
    "Music Recommendation Engine\n",
    "User Interface Development\n",
    "Integration and Testing\n",
    "Model Refinement\n",
    "Usage Instructions\n",
    "Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5d7343-2773-408e-9796-59e5482ed233",
   "metadata": {},
   "source": [
    "12. Deployment Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c437be76-6413-4c92-a249-4c24a04636e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Procfile for Heroku\n",
    "echo \"web: python app.py\" > Procfile\n",
    "\n",
    "# Create a requirements.txt file\n",
    "pip freeze > requirements.txt\n",
    "\n",
    "# Deploy to Heroku\n",
    "heroku create\n",
    "git init\n",
    "heroku git:remote -a your-heroku-app-name\n",
    "git add .\n",
    "git commit -m \"Initial commit\"\n",
    "git push heroku master\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82324ca-5fc6-43a9-ba50-2bcfc7a52254",
   "metadata": {},
   "source": [
    "Conclusion"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bb69ea2-96f8-4b80-9d52-2b6811d3b80d",
   "metadata": {},
   "source": [
    "By following these steps, you will develop a robust and user-friendly MoodforMusic application that detects user mood from images/videos and provides personalized music recommendations. The project includes comprehensive tasks from data collection to deployment, ensuring a complete end-to-end solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c259b-4791-429f-a014-9a8589f82ef1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
